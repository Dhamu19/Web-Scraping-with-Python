from bs4 import BeautifulSoup
import requests
import csv

source = requests.get('http://coreyms.com').text

soup = BeautifulSoup(source, 'lxml')

csv_file = open('Web_Scraping.csv', 'w')                        # to open the csv file

csv_writer = csv.writer(csv_file)                               # to pass in the csv file

csv_writer.writerow(['headline', 'summary', 'video_link'])      # to specify the header of the file (the column names)

for article in soup.find_all('article'):

    #print(article.prettify())

    headline = article.h2.a.text
    print(headline)

    summary = article.find('div', class_='entry-content').p.text
    print(summary)

    vid_src = article.find('iframe', class_='youtube-player')['src']

    vid_id = vid_src.split('/')[4]
    vid_id = vid_id.split('?')[0]

    yt_link = format('https://youtube.com/watch?v=vid_id')
    print(yt_link)

    print()

    csv_writer.writerow(['headline, summary, yt_link'])

csv_file.close()




